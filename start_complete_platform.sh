#!/bin/bash

# Complete FL Platform Startup Script
# Launches the integrated federated learning platform with AI assistant

clear

echo "ğŸ¤– Federated Learning Guardian Platform"
echo "========================================="
echo ""
echo "ğŸ¯ Complete AI-Powered Federated Learning System"
echo ""
echo "âœ¨ Features:"
echo "  â€¢ ChatGPT-like AI assistant explaining FL concepts"
echo "  â€¢ Real-world federated learning with PyTorch"
echo "  â€¢ Live AI integration (OpenAI, Anthropic, etc.)"
echo "  â€¢ Privacy-first offline mode option"
echo "  â€¢ MCP server for AI service coordination"
echo "  â€¢ LangGraph workflow visualization"
echo "  â€¢ Interactive network topology"
echo "  â€¢ Advanced graphics and animations"
echo ""
echo "ğŸ›¡ï¸ Privacy & Security:"
echo "  â€¢ Request offline mode for air-gapped environments"
echo "  â€¢ GDPR/HIPAA compliance features"
echo "  â€¢ End-to-end encryption"
echo "  â€¢ Local data processing only"
echo ""

# Set up environment
export PYTHONPATH="${PYTHONPATH}:$(pwd):$(pwd)/flower-offguard-uiota-demo/src:$(pwd)/agents"
export OFFLINE_MODE=0  # Can be changed via web interface

# Create necessary directories
mkdir -p logs
mkdir -p ~/.uiota

# Parse command line arguments
OFFLINE_MODE=false
PORT=8888
HOST="localhost"

while [[ $# -gt 0 ]]; do
    case $1 in
        --offline)
            OFFLINE_MODE=true
            export OFFLINE_MODE=1
            shift
            ;;
        --port)
            PORT="$2"
            shift 2
            ;;
        --host)
            HOST="$2"
            shift 2
            ;;
        -h|--help)
            echo "Usage: $0 [OPTIONS]"
            echo ""
            echo "Options:"
            echo "  --offline     Start in offline mode (maximum privacy)"
            echo "  --port PORT   Specify port (default: 8888)"
            echo "  --host HOST   Specify host (default: localhost)"
            echo "  -h, --help    Show this help message"
            echo ""
            exit 0
            ;;
        *)
            echo "Unknown option: $1"
            echo "Use --help for usage information"
            exit 1
            ;;
    esac
done

if [ "$OFFLINE_MODE" = true ]; then
    echo "ğŸ›¡ï¸ OFFLINE MODE ENABLED"
    echo "  â€¢ Maximum privacy and security"
    echo "  â€¢ No external network connections"
    echo "  â€¢ All processing happens locally"
    echo "  â€¢ Perfect for sensitive environments"
    echo ""
fi

echo "ğŸ”§ Checking system requirements..."

# Check Python version
PYTHON_VERSION=$(python3 -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')")
echo "  âœ… Python $PYTHON_VERSION detected"

# Check for required Python packages
echo "ğŸ“¦ Checking dependencies..."

# Core dependencies (always required)
python3 -c "import http.server, json, threading, webbrowser" 2>/dev/null
if [ $? -eq 0 ]; then
    echo "  âœ… Core Python libraries available"
else
    echo "  âŒ Missing core Python libraries"
    exit 1
fi

# Optional ML dependencies
ML_AVAILABLE=false
python3 -c "import torch, numpy" 2>/dev/null
if [ $? -eq 0 ]; then
    echo "  âœ… PyTorch available - real FL training enabled"
    ML_AVAILABLE=true
else
    echo "  âš ï¸ PyTorch not available - using simulation mode"
    echo "     Install with: pip install torch numpy"
fi

# Optional AI dependencies
AI_AVAILABLE=false
python3 -c "import openai" 2>/dev/null && python3 -c "import anthropic" 2>/dev/null
if [ $? -eq 0 ]; then
    echo "  âœ… AI libraries available - live AI integration enabled"
    AI_AVAILABLE=true
else
    echo "  âš ï¸ AI libraries not available - using mock responses"
    echo "     Install with: pip install openai anthropic langchain"
fi

echo ""
echo "ğŸš€ Starting Federated Learning Platform..."
echo ""
echo "ğŸ“Š System Configuration:"
echo "  â€¢ Host: $HOST"
echo "  â€¢ Port: $PORT"
echo "  â€¢ Offline Mode: $OFFLINE_MODE"
echo "  â€¢ ML Training: $([ "$ML_AVAILABLE" = true ] && echo "Real (PyTorch)" || echo "Simulation")"
echo "  â€¢ AI Integration: $([ "$AI_AVAILABLE" = true ] && echo "Live APIs" || echo "Mock Responses")"
echo ""

# Determine which launcher to use
if [ -f "integrated_fl_launcher.py" ]; then
    LAUNCHER="integrated_fl_launcher.py"
    echo "ğŸ¯ Using integrated launcher with AI assistant"
elif [ -f "enhanced_live_demo.py" ]; then
    LAUNCHER="enhanced_live_demo.py"
    echo "ğŸ¯ Using enhanced live demo launcher"
elif [ -f "simple_demo_launcher.py" ]; then
    LAUNCHER="simple_demo_launcher.py"
    echo "ğŸ¯ Using simple demo launcher"
else
    echo "âŒ No launcher found! Please ensure the launcher files exist."
    exit 1
fi

echo "ğŸŒ Platform will be available at: http://$HOST:$PORT"
echo "ğŸ“± Browser will open automatically"
echo ""
echo "ğŸ¤– AI Assistant Features:"
echo "  â€¢ Explains federated learning concepts"
echo "  â€¢ Guides you through the platform"
echo "  â€¢ Helps configure privacy settings"
echo "  â€¢ Provides real-time insights"
echo ""
echo "ğŸ›¡ï¸ Privacy Controls:"
echo "  â€¢ Request offline mode from the web interface"
echo "  â€¢ Configure API keys securely"
echo "  â€¢ Control data sharing preferences"
echo ""

# Add delay to let user read the information
echo "Starting in 3 seconds... (Press Ctrl+C to cancel)"
sleep 1
echo "Starting in 2 seconds..."
sleep 1
echo "Starting in 1 second..."
sleep 1

echo ""
echo "ğŸš€ LAUNCHING PLATFORM..."
echo "========================"

# Build launch command
LAUNCH_CMD="python3 $LAUNCHER --host $HOST --port $PORT"

if [ "$OFFLINE_MODE" = true ]; then
    LAUNCH_CMD="$LAUNCH_CMD --offline"
fi

# Launch the platform
echo "ğŸ“¡ Executing: $LAUNCH_CMD"
echo ""

# Execute the launch command
exec $LAUNCH_CMD

# This should not be reached, but just in case
echo ""
echo "ğŸ”„ Platform stopped"
echo "âœ… Cleanup complete"